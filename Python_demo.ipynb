{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Conditionally Risk-Averse Contextual Bandits Python tutorial"
      ],
      "metadata": {
        "id": "4ZvdqdGzhqGg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook we present the Python implementation of the SquareCB algorithm and the expectile loss."
      ],
      "metadata": {
        "id": "BEO67MXzD3NN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SquareCB algorithm with expectile loss\n",
        "\n",
        "The SquareCB algorithm tackles contextual bandit problems via reduction to regression. After observing the context at time *t*, the online regression oracle predicts losses for each action. It assigns higher probabilities to actions with lower predicted losses and the other way around. The exact weighting of actions can be read in the link and is implemented below.\n",
        "\n",
        "https://github.com/VowpalWabbit/vowpal_wabbit/wiki/Contextual-Bandit-Exploration-with-SquareCB"
      ],
      "metadata": {
        "id": "lYmV3pFt8op_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Return action distribution based on the predicted losses for playing each action\n",
        "def get_distribution(loss_predictions, gamma):\n",
        "  # Number of loss predictions = number of actions\n",
        "  K = len(loss_predictions) \n",
        "\n",
        "  # Set the first one as default value\n",
        "  minimum_predicted_loss = loss_predictions[0] \n",
        "\n",
        "  # Get the best action with the minumum predicted loss\n",
        "  for i in range(K):\n",
        "    if loss_predictions[i] <= minimum_predicted_loss:\n",
        "      #best_action = actions[i]\n",
        "      best_action_idx = i\n",
        "      minimum_predicted_loss = loss_predictions[i]\n",
        "\n",
        "  # Calculate probabilities over the actions\n",
        "  p_sum = 0\n",
        "  p = [] * K\n",
        "  for i in range(K):\n",
        "    if i == best_action_idx:\n",
        "      continue\n",
        "    p[i] = 1/(K+gamma*(loss_predictions[i]-minimum_predicted_loss))\n",
        "    p_sum += loss_predictions[i]\n",
        "\n",
        "  # The remaining probability is assigned to the best action\n",
        "  p[best_action_idx] = 1 - p_sum\n",
        "\n",
        "  return p"
      ],
      "metadata": {
        "id": "EQ-U-ky5gtyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Expectile loss of the regression oracle\n",
        "def expectile_loss(q, prediction, true_value):\n",
        "  error = label - prediction\n",
        "  loss = 1/2 * (label-prediction)**2 # Squared loss\n",
        "  if error < 0:\n",
        "    return q * loss\n",
        "  return  (1 - q) * loss"
      ],
      "metadata": {
        "id": "kkjg1MbsDlIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gamma_scale and gamma_exponent: two hyperparameters of the SquareCB algorithm\n",
        "gamma_scale = 1000\n",
        "gamma_exponent = 0.5\n",
        "\n",
        "# Expectile parameter\n",
        "q = 0.2\n",
        "\n",
        "for t in range(T):\n",
        "  # Observe context \n",
        "  context = get_context() \n",
        "\n",
        "  # Algorithm predicts losses for the available actions\n",
        "  loss_predictions = alg.predict(context) \n",
        "\n",
        "  # Larger gamma leads to a greedier algorithm\n",
        "  gamma = gamma_scale * t**gamma_exponent \n",
        "\n",
        "  # Calculate action distribution from predicted losses\n",
        "  distr = get_distribution(loss_predictions, gamma) \n",
        "\n",
        "  # Sample an action from the action distribution and also return the predicted loss for that action \n",
        "  action, predicted_loss = sample_action(distr)\n",
        "\n",
        "  # Observe true loss from the played action\n",
        "  observed_loss = getloss(context, action) \n",
        "\n",
        "  # The default SquareCB algorithm uses squared loss\n",
        "  # To be risk-averse, we use the expectile loss instead of squared loss\n",
        "  # Calculate expectile loss, q is the expectile parameter\n",
        "  # Note: with q=0.5, it results in the default squared loss\n",
        "  loss = expectile_loss(q, predicted_loss, observed_loss) \n",
        "\n",
        "  # Update the algorithm with the context-action-loss combination\n",
        "  alg.update(context, action, loss) "
      ],
      "metadata": {
        "id": "tTcu_E_lypT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Expectile loss"
      ],
      "metadata": {
        "id": "s5-FHfzb_4IW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we show the expectile loss and its connection to the risk measure of EVaR."
      ],
      "metadata": {
        "id": "fj-CU50rE6_s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.optimize import minimize_scalar"
      ],
      "metadata": {
        "id": "KnTzXbzHWjBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o6vi9iBwWR42"
      },
      "outputs": [],
      "source": [
        "# Equation of the expectile loss\n",
        "# It's an asymmetric function with an expectile parameter q\n",
        "def f(m, data):\n",
        "    return q * np.sum(np.square(np.clip(data - m, a_min=0, a_max=None))) + (1 - q) * np.sum(np.square(np.clip(m - data, a_min=0, a_max=None)))  \n",
        "\n",
        "# The minimizer of the above equation is the expectile (EVaR)\n",
        "def evar(data):\n",
        "  res = minimize_scalar(lambda m: f(m, data), bounds=(np.min(data), np.max(data)), method='bounded')\n",
        "  return res.x"
      ]
    }
  ]
}